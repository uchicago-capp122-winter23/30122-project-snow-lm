import pandas as pd

################################################################################
### Exploration of FEMA public assistance federal obligation data  ###
project_summaries = pd.read_csv("PublicAssistanceFundedProjectsSummaries.csv")

# Initial Exploratory 
project_summaries.head()
list(project_summaries.columns)

# Code for reshaping the data to be wide by disaster type rather than long
pivoted = collapsed_summaries.pivot(index="state", columns="incidentType", values="federalObligatedAmount")
pivoted.sum(axis='columns') #returns total by state
print(pivoted)


## code for checking merge with disastr IDS

len(project_summaries['disasterNumber'].unique()) #1544
len(set(disaster_list))  ##2758, harsh has a longer time frame, and many 
    #disasters dont have public assistance
len(project_summaries['disasterNumber'].unique()) #1374

## Duplicate removal code 
    # Drop duplicate observations
    # Duplicate observations appear for "snow" vs "snowstorm" disaster types,
    # and "storm vs storm (s) disaster types
    project_summaries.drop_duplicates(subset = ['disasterNumber', 'declarationDate',
        'county', 'applicantName', 'educationApplicant', 'numberOfProjects',
        'fed_amount'], keep = 'first', inplace = True)

################################################################################
